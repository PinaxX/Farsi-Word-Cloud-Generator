{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Cloud.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-fFaCK7BEDu"
      },
      "source": [
        "snscrape --jsonl --since 2021-05-01 twitter-hashtag \"انتخابات until:2021-05-27\" > election.json\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Gh7E_QAChS"
      },
      "source": [
        "filename = 'election'\n",
        "hashtag = 'انتخابات'\n",
        "min_word_length = 2\n",
        "\n",
        "width = 800\n",
        "height = 500\n",
        "background_color = 'white'\n",
        "min_font_size = 10\n",
        "prefer_horizontal = 1."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIDOpmLDRFF_"
      },
      "source": [
        "%%capture\n",
        "!pip install stopwords_guilannlp\n",
        "!pip install hazm\n",
        "!unrar e $filename\n",
        "!pip install wordcloud-fa\n",
        "\n",
        "from stopwords_guilannlp import stopwords_output\n",
        "import re\n",
        "from hazm import *\n",
        "import json\n",
        "from wordcloud_fa import WordCloudFa"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayNTvjShNEkI"
      },
      "source": [
        "stopwords = stopwords_output(\"Persian\", output=\"set\")\n",
        "normalizer = Normalizer()\n",
        "\n",
        "def preprocess(text):\n",
        "  text = text.replace('\\u200c', ' ')\n",
        "  text = text.replace('<br/>', '\\n')\n",
        "  text = text.replace('\\n', ' ')\n",
        "  text = normalizer.normalize(text)\n",
        "  text = re.sub(r\"[^آابپتثجچحخدذرزژسشصضطءئظعغفقکگلمنوهی]+\", \" \", text)\n",
        "  text = text.strip()\n",
        "  tokens = text.split()\n",
        "  tmp = []\n",
        "  for token in tokens:\n",
        "    if token not in stopwords and len(token) > min_word_length and token != hashtag:\n",
        "      tmp.append(token)\n",
        "  text = \" \".join(tmp)\n",
        "  return text\n",
        "\n",
        "text = \"\"\n",
        "\n",
        "with open(filename + '.json', 'rb') as f:\n",
        "  for line in f:\n",
        "    try:\n",
        "      tweet = json.loads(line)\n",
        "      text += preprocess(tweet['content']) + ' '\n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z4Qb9-AZh_m"
      },
      "source": [
        "wordcloud = WordCloudFa(width=width, height=height,\n",
        "                        background_color=background_color,\n",
        "                        stopwords=stopwords,\n",
        "                        min_font_size=min_font_size,\n",
        "                        prefer_horizontal=prefer_horizontal)\n",
        "wc = wordcloud.generate(text)\n",
        "image = wc.to_image()\n",
        "image.show()\n",
        "image.save('wordcloud.png')"
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}